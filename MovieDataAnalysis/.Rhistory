library(rpart)
library(caret)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m.rp <- rpart(a~b+c+d+e+f+g+h+i, data=d.a, method = "class" )
pred.y <- predict(m.rp, d.t[,-1], type = "class")
cfm <- table(d.t$a, pred.y)
train.err <- (sum(cfm)-sum(diag(cfm)))/sum(cfm)
cfm
train.err
(1-train.err)*100
library(rpart)
library(caret)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m.rp <- rpart(a~b+c+d+e+f+g+h+i, data=d.a, method = "class" )
pred.y <- predict(m.rp, d.t[,-1], type = "class")
cfm <- table(d.t$a, pred.y)
train.err <- (sum(cfm)-sum(diag(cfm)))/sum(cfm)
cfm
train.err
(1-train.err)*100
#decisionTree
library(nnet)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
#decisionTree
library(nnet)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
#LDA(DiscriminantAnalysis)
library(MASS)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
fit <- lda(a ~ b+c+d+e+f+g+h+i , data=d.a)
pred = predict(fit, d.t)
pred_a = pred$class
table(pred_a,d.t$a)
ct <- table(pred_a,d.t$a)
sum(diag(prop.table(ct)))
#K_Nearest_Neighbors
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
training_data<-d.a[,-1]
test_data<-d.t[,-1]
class <- d.a[,1]
m1 <-knn(training_data,test_data,class,13)
target<-d.t[,1]
table(target,m1)
ct <- table(target,m1)
sum(diag(prop.table(ct)))
#K_Nearest_Neighbors
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
library(class)
training_data<-d.a[,-1]
test_data<-d.t[,-1]
class <- d.a[,1]
m1 <-knn(training_data,test_data,class,13)
target<-d.t[,1]
table(target,m1)
ct <- table(target,m1)
sum(diag(prop.table(ct)))
#K_Nearest_Neighbors
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
library(class)
training_data<-d.a[,-1]
test_data<-d.t[,-1]
class <- d.a[,1]
m1 <-knn(training_data,test_data,class,13)
target<-d.t[,1]
table(target,m1)
ct <- table(target,m1)
sum(diag(prop.table(ct)))
#LDA(DiscriminantAnalysis)
library(MASS)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
fit <- lda(a ~ b+c+d+e+f+g+h+i , data=d.a)
pred = predict(fit, d.t)
pred_a = pred$class
table(pred_a,d.t$a)
ct <- table(pred_a,d.t$a)
sum(diag(prop.table(ct)))
#decisionTree
library(nnet)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
#decisionTree
library(nnet)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
#명목형logit분석
library(nnet)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
imp <- varImp(m)
rownames(imp)[order(imp$Overall, decreasing=True)][1:5]
#명목형logit분석
library(nnet)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
imp <- varImp(m)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
#decisionTree
library(rpart)
library(caret)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m.rp <- rpart(a~b+c+d+e+f+g+h+i, data=d.a, method = "class" )
pred.y <- predict(m.rp, d.t[,-1], type = "class")
cfm <- table(d.t$a, pred.y)
train.err <- (sum(cfm)-sum(diag(cfm)))/sum(cfm)
cfm
train.err
(1-train.err)*100
library(party)
dtree<-ctree(a~. , d.a)
plot(dtree)
imp <- varImp(m.rp)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
install.packages("party")
#decisionTree
library(rpart)
library(caret)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m.rp <- rpart(a~b+c+d+e+f+g+h+i, data=d.a, method = "class" )
pred.y <- predict(m.rp, d.t[,-1], type = "class")
cfm <- table(d.t$a, pred.y)
train.err <- (sum(cfm)-sum(diag(cfm)))/sum(cfm)
cfm
train.err
(1-train.err)*100
library(party)
dtree<-ctree(a~. , d.a)
plot(dtree)
imp <- varImp(m.rp)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
library(nnet)
d.a<-read.csv("inflatedTrainSet.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
imp <- varImp(m)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
# logit
library(party)
library(nnet)
d.a<-read.csv("inflatedTrainSet.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
imp <- varImp(m)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
#logit
library(nnet)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
imp <- varImp(m)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
#decisionTree
library(rpart)
library(caret)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m.rp <- rpart(a~b+c+d+e+f+g+h+i, data=d.a, method = "class" )
pred.y <- predict(m.rp, d.t[,-1], type = "class")
cfm <- table(d.t$a, pred.y)
train.err <- (sum(cfm)-sum(diag(cfm)))/sum(cfm)
cfm
train.err
(1-train.err)*100
library(party)
dtree<-ctree(a~. , d.a)
plot(dtree)
imp <- varImp(m.rp)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
#logit
library(caret)
library(nnet)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
imp <- varImp(m)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
#logit
library(caret)
library(nnet)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
imp <- varImp(m)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
#logit
library(caret)
library(nnet)
d.a<-read.csv("Inflatedtrainset.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
imp <- varImp(m)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
#logit
library(caret)
library(nnet)
d.a<-read.csv("inflatedtrainset.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
imp <- varImp(m)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
#logit
library(caret)
library(nnet)
d.a<-read.csv("inflatedtrainset.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
imp <- varImp(m)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
#decisionTree
library(rpart)
library(caret)
d.a<-read.csv("inflatedtrainset.csv")
d.t<-read.csv("testset.csv")
m.rp <- rpart(a~b+c+d+e+f+g+h+i, data=d.a, method = "class" )
pred.y <- predict(m.rp, d.t[,-1], type = "class")
cfm <- table(d.t$a, pred.y)
train.err <- (sum(cfm)-sum(diag(cfm)))/sum(cfm)
cfm
train.err
(1-train.err)*100
library(party)
dtree<-ctree(a~. , d.a)
plot(dtree)
imp <- varImp(m.rp)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
#LDA(DiscriminantAnalysis)
library(MASS)
d.a<-read.csv("inflatedtrainset.csv")
d.t<-read.csv("testset.csv")
fit <- lda(a ~ b+c+d+e+f+g+h+i , data=d.a)
pred = predict(fit, d.t)
pred_a = pred$class
table(pred_a,d.t$a)
ct <- table(pred_a,d.t$a)
sum(diag(prop.table(ct)))
#K_Nearest_Neighbors
d.a<-read.csv("inflatedtrainset.csv")
d.t<-read.csv("testset.csv")
library(class)
training_data<-d.a[,-1]
test_data<-d.t[,-1]
class <- d.a[,1]
m1 <-knn(training_data,test_data,class,13)
target<-d.t[,1]
table(target,m1)
ct <- table(target,m1)
sum(diag(prop.table(ct)))
