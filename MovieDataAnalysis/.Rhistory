cfm
train.err
(1-train.err)*100
library(party)
#dtree<-ctree(a~. , d.a)
#plot(dtree)
imp <- varImp(m.rp)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
confusionMatrix(pred.y, d.t$a)
prob = (sum(cfm[4,1:3])+sum(cfm[5,1:4]))/sum(cfm[4:5,1:5])
prob
#LDA(DiscriminantAnalysis)
library(MASS)
d.a<-read.csv("inflatedtrainset.csv")
d.t<-read.csv("testset.csv")
fit <- lda(a ~ b+c+d+e+f+g+h+i , data=d.a)
pred = predict(fit, d.t)
pred_a = pred$class
table(pred_a,d.t$a)
cfm <- table(pred_a,d.t$a)
sum(diag(prop.table(ct)))
confusionMatrix(pred_a, d.t$a)
prob = (sum(cfm[4,1:3])+sum(cfm[5,1:4]))/sum(cfm[4:5,1:5])
prob
#K_Nearest_Neighbors
d.a<-read.csv("inflatedtrainset.csv")
d.t<-read.csv("testset.csv")
library(class)
training_data<-d.a[,-1]
test_data<-d.t[,-1]
class <- d.a[,1]
m1 <-knn(training_data,test_data,class,13)
target<-d.t[,1]
table(m1,target)
cfm <- table(m1,target)
sum(diag(prop.table(ct)))
confusionMatrix(m1,target)
prob = (sum(cfm[4,1:3])+sum(cfm[5,1:4]))/sum(cfm[4:5,1:5])
prob
fm[2,1])+sum(cfm[3,1:2])+sum(cfm[4,1:3])+sum(cfm[5,1:4])) / sum(cfm[1:5,1:5])
prob_1
prob_1= (sum(cfm[2,1])+sum(cfm[3,1:2])+sum(cfm[4,1:3])+sum(cfm[5,1:4])) / sum(cfm[1:5,1:5])
prob_1
# logit
library(caret)
library(nnet)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
cfm <- xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
imp <- varImp(m)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
confusionMatrix(predicted, d.t$a)
prob = (sum(cfm[4,1:3])+sum(cfm[5,1:4]))/sum(cfm[4:5,1:5])
prob
prob_1= (sum(cfm[2,1])+sum(cfm[3,1:2])+sum(cfm[4,1:3])+sum(cfm[5,1:4])) / sum(cfm[1:5,1:5])
prob_1
#decisionTree
library(rpart)
library(caret)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m.rp <- rpart(a~b+c+d+e+f+g+h+i, data=d.a, method = "class" )
pred.y <- predict(m.rp, d.t[,-1], type = "class")
cfm <- table(d.t$a, pred.y)
train.err <- (sum(cfm)-sum(diag(cfm)))/sum(cfm)
cfm
train.err
(1-train.err)*100
library(party)
dtree<-ctree(a~. , d.a)
plot(dtree)
imp <- varImp(m.rp)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
confusionMatrix(pred.y, d.t$a)
prob = (sum(cfm[4,1:3])+sum(cfm[5,1:4]))/sum(cfm[4:5,1:5])
prob
prob_1= (sum(cfm[2,1])+sum(cfm[3,1:2])+sum(cfm[4,1:3])+sum(cfm[5,1:4])) / sum(cfm[1:5,1:5])
prob_1
#LDA(DiscriminantAnalysis)
library(MASS)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
fit <- lda(a ~ b+c+d+e+f+g+h+i , data=d.a)
pred = predict(fit, d.t)
pred_a = pred$class
table(pred_a,d.t$a)
cfm <- table(pred_a,d.t$a)
sum(diag(prop.table(ct)))
confusionMatrix(pred_a, d.t$a)
prob = (sum(cfm[4,1:3])+sum(cfm[5,1:4]))/sum(cfm[4:5,1:5])
prob
prob_1= (sum(cfm[2,1])+sum(cfm[3,1:2])+sum(cfm[4,1:3])+sum(cfm[5,1:4])) / sum(cfm[1:5,1:5])
prob_1
#K_Nearest_Neighbors
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
library(class)
training_data<-d.a[,-1]
test_data<-d.t[,-1]
class <- d.a[,1]
m1 <-knn(training_data,test_data,class,13)
target<-d.t[,1]
table(m1,target)
cfm <- table(m1,target)
sum(diag(prop.table(ct)))
confusionMatrix(m1,target)
prob = (sum(cfm[4,1:3])+sum(cfm[5,1:4]))/sum(cfm[4:5,1:5])
prob
prob_1= (sum(cfm[2,1])+sum(cfm[3,1:2])+sum(cfm[4,1:3])+sum(cfm[5,1:4])) / sum(cfm[1:5,1:5])
prob_1
#K_Nearest_Neighbors
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
library(class)
training_data<-d.a[,-1]
test_data<-d.t[,-1]
class <- d.a[,1]
m1 <-knn(training_data,test_data,class,13)
target<-d.t[,1]
table(m1,target)
cfm <- table(m1,target)
sum(diag(prop.table(ct)))
confusionMatrix(m1,target)
prob= (sum(cfm[2,1])+sum(cfm[3,1:2])+sum(cfm[4,1:3])+sum(cfm[5,1:4])) / sum(cfm[1:5,1:5])
prob
sum(cfm[1:5,1:5]
sum(cfm[1:5,1:5])
#prob = (sum(cfm[4,1:3])+sum(cfm[5,1:4]))/sum(cfm[4:5,1:5])
sum(cfm[1:5,1:5])
sum(cfm[2,1])+sum(cfm[3,1:2])+sum(cfm[4,1:3])+sum(cfm[5,1:4])
cfm[2,1]
cfm[3,1:2]
cfm[3,1]
cfm[1,3]
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
prob - 0.01459486663311524911927528938098
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
#K_Nearest_Neighbors
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
library(class)
training_data<-d.a[,-1]
test_data<-d.t[,-1]
class <- d.a[,1]
m1 <-knn(training_data,test_data,class,13)
target<-d.t[,1]
table(m1,target)
cfm <- table(m1,target)
sum(diag(prop.table(ct)))
confusionMatrix(m1,target)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
#K_Nearest_Neighbors
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
library(class)
training_data<-d.a[,-1]
test_data<-d.t[,-1]
class <- d.a[,1]
m1 <-knn(training_data,test_data,class,13)
target<-d.t[,1]
table(m1,target)
cfm <- table(m1,target)
sum(diag(prop.table(cfm)))
confusionMatrix(m1,target)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
#K_Nearest_Neighbors
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
library(class)
training_data<-d.a[,-1]
test_data<-d.t[,-1]
class <- d.a[,1]
m1 <-knn(training_data,test_data,class,13)
target<-d.t[,1]
table(m1,target)
cfm <- table(m1,target)
sum(diag(prop.table(cfm)))
confusionMatrix(m1,target)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
class <- d.a[,1]
#K_Nearest_Neighbors
d.a<-read.csv("inflatedtrainset.csv")
d.t<-read.csv("testset.csv")
library(class)
training_data<-d.a[,-1]
test_data<-d.t[,-1]
class <- d.a[,1]
m1 <-knn(training_data,test_data,class,13)
target<-d.t[,1]
table(m1,target)
cfm <- table(m1,target)
sum(diag(prop.table(cfm)))
confusionMatrix(m1,target)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
#LDA(DiscriminantAnalysis)
library(MASS)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
fit <- lda(a ~ b+c+d+e+f+g+h+i , data=d.a)
pred = predict(fit, d.t)
pred_a = pred$class
table(pred_a,d.t$a)
cfm <- table(pred_a,d.t$a)
sum(diag(prop.table(cfm)))
confusionMatrix(pred_a, d.t$a)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
#LDA(DiscriminantAnalysis)
library(MASS)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
fit <- lda(a ~ b+c+d+e+f+g+h+i , data=d.a)
pred = predict(fit, d.t)
pred_a = pred$class
table(pred_a,d.t$a)
cfm <- table(pred_a,d.t$a)
sum(diag(prop.table(cfm)))
confusionMatrix(pred_a, d.t$a)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
#LDA(DiscriminantAnalysis)
library(MASS)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
fit <- lda(a ~ b+c+d+e+f+g+h+i , data=d.a)
pred = predict(fit, d.t)
pred_a = pred$class
table(pred_a,d.t$a)
cfm <- table(pred_a,d.t$a)
sum(diag(prop.table(cfm)))
confusionMatrix(pred_a, d.t$a)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
#LDA(DiscriminantAnalysis)
library(MASS)
d.a<-read.csv("inflatedtrainset.csv")
d.t<-read.csv("testset.csv")
fit <- lda(a ~ b+c+d+e+f+g+h+i , data=d.a)
pred = predict(fit, d.t)
pred_a = pred$class
table(pred_a,d.t$a)
cfm <- table(pred_a,d.t$a)
sum(diag(prop.table(cfm)))
confusionMatrix(pred_a, d.t$a)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
# logit
library(caret)
library(nnet)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
cfm <- xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
imp <- varImp(m)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
confusionMatrix(predicted, d.t$a)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
# logit
library(caret)
library(nnet)
d.a<-read.csv("inflatedtrainset.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
cfm <- xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
imp <- varImp(m)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
confusionMatrix(predicted, d.t$a)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
#decisionTree
library(rpart)
library(caret)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m.rp <- rpart(a~b+c+d+e+f+g+h+i, data=d.a, method = "class" )
pred.y <- predict(m.rp, d.t[,-1], type = "class")
cfm <- table(d.t$a, pred.y)
train.err <- (sum(cfm)-sum(diag(cfm)))/sum(cfm)
cfm
train.err
(1-train.err)*100
library(party)
dtree<-ctree(a~. , d.a)
plot(dtree)
imp <- varImp(m.rp)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
confusionMatrix(pred.y, d.t$a)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
#decisionTree
library(rpart)
library(caret)
d.a<-read.csv("inflatedtrainset.csv")
d.t<-read.csv("testset.csv")
m.rp <- rpart(a~b+c+d+e+f+g+h+i, data=d.a, method = "class" )
pred.y <- predict(m.rp, d.t[,-1], type = "class")
cfm <- table(d.t$a, pred.y)
train.err <- (sum(cfm)-sum(diag(cfm)))/sum(cfm)
cfm
train.err
(1-train.err)*100
library(party)
#dtree<-ctree(a~. , d.a)
#plot(dtree)
imp <- varImp(m.rp)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
confusionMatrix(pred.y, d.t$a)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
# logit
library(caret)
library(nnet)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
cfm <- xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
imp <- varImp(m)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
confusionMatrix(predicted, d.t$a)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
#decisionTree
library(rpart)
library(caret)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m.rp <- rpart(a~b+c+d+e+f+g+h+i, data=d.a, method = "class" )
pred.y <- predict(m.rp, d.t[,-1], type = "class")
cfm <- table(d.t$a, pred.y)
train.err <- (sum(cfm)-sum(diag(cfm)))/sum(cfm)
cfm
train.err
(1-train.err)*100
library(party)
dtree<-ctree(a~. , d.a)
plot(dtree)
imp <- varImp(m.rp)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
confusionMatrix(pred.y, d.t$a)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
#LDA(DiscriminantAnalysis)
library(MASS)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
fit <- lda(a ~ b+c+d+e+f+g+h+i , data=d.a)
pred = predict(fit, d.t)
pred_a = pred$class
table(pred_a,d.t$a)
cfm <- table(pred_a,d.t$a)
sum(diag(prop.table(cfm)))
confusionMatrix(pred_a, d.t$a)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
#K_Nearest_Neighbors
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
library(class)
training_data<-d.a[,-1]
test_data<-d.t[,-1]
class <- d.a[,1]
m1 <-knn(training_data,test_data,class,13)
target<-d.t[,1]
table(m1,target)
cfm <- table(m1,target)
sum(diag(prop.table(cfm)))
confusionMatrix(m1,target)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
#K_Nearest_Neighbors
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
library(class)
training_data<-d.a[,-1]
test_data<-d.t[,-1]
class <- d.a[,1]
m1 <-knn(training_data,test_data,class,13)
target<-d.t[,1]
table(m1,target)
cfm <- table(m1,target)
sum(diag(prop.table(cfm)))
confusionMatrix(m1,target)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
# logit
library(caret)
library(nnet)
d.a<-read.csv("inflatedtrainset.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
cfm <- xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
imp <- varImp(m)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
confusionMatrix(predicted, d.t$a)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
#decisionTree
library(rpart)
library(caret)
d.a<-read.csv("inflatedtrainset.csv")
d.t<-read.csv("testset.csv")
m.rp <- rpart(a~b+c+d+e+f+g+h+i, data=d.a, method = "class" )
pred.y <- predict(m.rp, d.t[,-1], type = "class")
cfm <- table(d.t$a, pred.y)
train.err <- (sum(cfm)-sum(diag(cfm)))/sum(cfm)
cfm
train.err
(1-train.err)*100
library(party)
#dtree<-ctree(a~. , d.a)
#plot(dtree)
imp <- varImp(m.rp)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
confusionMatrix(pred.y, d.t$a)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
#LDA(DiscriminantAnalysis)
library(MASS)
d.a<-read.csv("inflatedtrainset.csv")
d.t<-read.csv("testset.csv")
fit <- lda(a ~ b+c+d+e+f+g+h+i , data=d.a)
pred = predict(fit, d.t)
pred_a = pred$class
table(pred_a,d.t$a)
cfm <- table(pred_a,d.t$a)
sum(diag(prop.table(cfm)))
confusionMatrix(pred_a, d.t$a)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
#K_Nearest_Neighbors
d.a<-read.csv("inflatedtrainset.csv")
d.t<-read.csv("testset.csv")
library(class)
training_data<-d.a[,-1]
test_data<-d.t[,-1]
class <- d.a[,1]
m1 <-knn(training_data,test_data,class,13)
target<-d.t[,1]
table(m1,target)
cfm <- table(m1,target)
sum(diag(prop.table(cfm)))
confusionMatrix(m1,target)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
# logit
library(caret)
library(nnet)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
cfm <- xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
imp <- varImp(m)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
confusionMatrix(predicted, d.t$a)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
# logit
library(caret)
library(nnet)
d.a<-read.csv("inflatedtrainset.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
cfm <- xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
imp <- varImp(m)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
confusionMatrix(predicted, d.t$a)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
# logit
library(caret)
library(nnet)
d.a<-read.csv("trainset.csv")
d.t<-read.csv("testset.csv")
m <- multinom(a~.,data=d.a)
multinom(formula = a ~.,data=d.a)
predicted <- predict(m, newdata=d.t)
cfm <- xtabs(~predicted + d.t$a)
sum ( predicted == d.t $ a ) / NROW ( predicted )
imp <- varImp(m)
rownames(imp)[order(imp$Overall, decreasing="True")][1:5]
confusionMatrix(predicted, d.t$a)
prob= (sum(cfm[2,1])+sum(cfm[1:2,3])+sum(cfm[1:3,4])+sum(cfm[1:4,5])) / sum(cfm[1:5,1:5])
prob
